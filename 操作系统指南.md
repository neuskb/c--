# 操作系统指南

## 并发并行区别
并发：在一个核上，处理多个任务
并行：多个核上执行多个任务

## 进程
### 进程的状态
* 运行状态：该时刻进程占用cpu
* 就绪状态：可运行，由于其他进程处于运行状态而暂时停止运行
* 阻塞状态：该进程正在等待某一事件发生而暂时停止运行，这个时候，即使给它cpu控制权，它也无法运行
其他两种状态：
* 创建状态：进程正在被创建时的状态
* 结束状态：进程正在从系统中消失时的状态

如果有大量处于阻塞状态的进程，可能会占用物理内存空间。所以在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。这个时候又需要一个新的状态，来描述进程没有占用实际的物理内存空间，这个就是==挂起状态==。
* 挂起状态分为两种：
    * 阻塞挂起状态：进程在硬盘等待某个事件出现
    * 就绪挂起状态：进程在硬盘，但只要进入内存，就立刻运行
导致进程挂起的原因还包括如下：
* 通过sleep让进程间歇性挂起，设置了定时器 ，到期唤醒进程
* 用户希望挂起一个程序的执行，比如在linux中用ctrl+z挂起进程

### 进程的控制结构

在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的。
PCB是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个PCB，如果进程消失，PCB也会随之消失。

1. PCB包含信息：

* 进程描述信息：进程标识符、用户标识符
* 进程控制和管理信息：进程当前状态、进程优先级
* 资源分配清单
* cpu相关信息

2. PCB如何组织：
* 把所有处于就绪状态的进程链在一起，就是就绪队列
* 把所有因等待某事件而处于等待状态的进程链在一起，就是阻塞队列

通过链表方式组织，把具有相同状态的进程链在一起，组成各种队列。另外还有索引的方式：将同一状态的进程组织在一个索引表中，索引表指向相应的PCB，不同状态对应不同的索引表。一般都会选择链表，进程创建销毁，链表能更加灵活的插入和删除。

### 进程的控制
1. 创建进程

操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时也会终止其所有的子进程。

创建进程的过程如下：
    
* 为新进程分配一个唯一的进程标识号，并申请一个空白的PCB，PCB是有限的，若申请失败则创建失败
* 为进程分配资源，如果资源不足，进程会进入等待状态，以等待资源
* 初始化PCB
* 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行
    
    
2. 终止进程

终止进程三种方式：正常结束，异常结束，以及外界干预（信号kill掉）

终止进程过程如下：
* 查找需要终止进程的PCB
* 如果处于执行状态，则立即终止该进程的执行，然后将CPU资源分配给其他进程
* 如果其还有子进程，则应将其所有子进程和终止
* 将该进程所拥有的全部资源归还给父进程或操作系统
* 将其从PCB所在队列中删除

3. 阻塞进程

当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒

阻塞进程过程如下：
* 找到将要被阻塞进程标识号对应的PCB
* 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行
* 将该PCB插入到阻塞队列中去

4. 唤醒进程

处于阻塞态的进程不可能叫醒自己，需要别的进程发消息给它。

唤醒过程如下：
* 在该时间的阻塞队列中找到相应进程的PCB
* 将其从阻塞队列中移出，并置其状态为就绪状态
* 把该PCB插入到就绪队列中，等待调度程序调度

### 进程上下文切换
各个进程之间是共享CPU资源的，在不同的时候进程之间需要切换，让不同的进程可以在cpu执行，这个一个进程切换到另一个进程运行，称为进程的上下文切换。

1. CPU上下文切换分为：
* 进程上下文切换
* 线程上下文切换
* 中断上下文切换

进程是由内核管理和调度的，所以进程的切换只能发生在内核态。

所以，进程的上下文切换不仅包含了虚拟内存，栈，全局变量等用户空间的资源，还包括了内核堆栈，寄存器等内核空间的资源。

通常会把交换的信息保存在进程的PCB，当要运行另外一个进程的时候，我们需要从这个进程的PCB取出上下文，然后恢复到CPU中，这使得这个进程可以继续执行。

2. 发生上下文切换的场景：
* 为了保证所有进程可以得到公平调度， CPU 时间被划分为⼀段段的时间⽚，这些时间⽚
再被轮流分配给各个进程。这样，当某个进程的时间⽚耗尽了，进程就从运⾏状态变为就
绪状态，系统从就绪队列选择另外⼀个进程运⾏；
* 进程在系统资源不⾜（⽐如内存不⾜）时，要等到资源满⾜后才可以运⾏，这个时候进程也会被挂起，并由系统调度其他进程运⾏；
* 当进程通过睡眠函数 sleep 这样的⽅法将⾃⼰主动挂起时，⾃然也会重新调度；
* 当有优先级更⾼的进程运⾏时，为了保证⾼优先级进程的运⾏，当前进程会被挂起，由⾼优先级进程来运⾏；
* 发⽣硬件中断时， CPU 上的进程会被中断挂起，转⽽执⾏内核中的中断服务程序；


## 线程
### 什么是线程？

线程是进程当中的一条执行流程。同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。

### 线程优缺点

线程优点：
* 一个进程中可以同时存在多个线程
* 各个线程之间可以并发执行
* 各个线程之间可以共享地址空间和文件等资源

线程的缺点：
* 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃

3. 线程和进程的比较
* 进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；
* 进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
* 线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
* 线程能减少并发执⾏的时间和空间开销；

## 调度
### 调度时机
* 进程状态变化的时候
* 非抢占式调度
* 抢占式调度

### 调度原则
* CPU利用率
* 系统吞吐量
* 周转时间
* 等待时间
* 响应时间

目的就是要使得进程要快！

### 调度算法
* 先来先服务（First Come First Seved, FCFS）
* 最短作业优先（Shortest Job First, SJF）
* ⾼响应⽐优先（Highest Response Ratio Next, HRRN）
* 时间⽚轮转（Round Robin, RR）
* 最⾼优先级（Highest Priority First， HPF）
* 多级反馈队列（Multilevel Feedback Queue）

## 进程间通信
每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。
## 管道
* 传输数据是单向的
* 通信方式效率低，不适合进程间频繁的交换数据
* 匿名管道，它的通信范围是存在父子关系，管道没有实体，只能通过fork来复制父进程fd文件描述符，来达到通信的目的
* 命名管道，可以在不相关的进程间也能相互通信，因为命令管道，提前创建了
⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信

不管是匿名管道还是命名管道，进程写⼊的数据都是缓存在内核中，另⼀个进程读取数据时候⾃然也是从内核中获取，同时通信数据都遵循先进先出原则，不⽀持lseek之类的⽂件定位操作。

## 消息队列
消息队列是保存在内核中的消息链表。

不足：
* 通信不及时
* 附件大小有限制
* 不适合比较大数据的传输
* 通信过程中，存在用户态和内核态之间的数据拷贝开销

## 共享内存

消息队列的读取和写入的过程，都会发生用户态和内核态之间的消息拷贝过程。共享内存的方式，就很好的解决了这个问题。

现代操作系统，对于内存管理，采⽤的是虚拟内存技术，也就是每个进程都有⾃⼰独⽴的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和进程 B 的虚拟地址是⼀样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。

共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了。大大提高了进程间的通信速度。

## 信号量

用了共享内存的通信方式，带来新的问题，如果多个进程同时修改同一个共享内存，很有可能就冲突了。为了防止多进程竞争共享资源，所以需要保护机制，信号量就实现了这个保护机制。

信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。

信号量表示资源的数量，控制信号量的⽅式有两种原⼦操作：
* ⼀个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量<0，则表明资源已被占
⽤，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使⽤，进程可正常继
续执⾏。
* 另⼀个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 <=0，则表明当前有
阻塞中的进程，于是会将该进程唤醒运⾏；相加后如果信号量 > 0，则表明当前没有阻塞
中的进程；

信号初始化为 1 ，就代表着是互斥信号量。信号初始化为 0 ，就代表着是同步信号量。

## 信号

对于异常情况下的工作模式，需要用信号的方式来通知进程。信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某⼀进程，⼀旦有信号产⽣，我们就有下⾯这⼏种，⽤户进程对信号的处理⽅式。

* 执行默认操作。Linux 对每种信号都规定了默认操作，例如，上⾯列表中的 SIGTERM 信
号，就是终⽌进程的意思
* 捕捉信号。我们可以为信号定义⼀个信号处理函数。当信号发⽣时，我们就执⾏相应的信号处理函数
* 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应⽤进程⽆法捕捉和忽略的，即SIGKILL和SEGSTOP，它们⽤于在任何时候中断或结束某⼀进程。

## socket

前⾯提到的管道、消息队列、共享内存、信号量和信号都是在同⼀台主机上进⾏进程间通
信，那要想跨⽹络与不同主机上的进程之间通信，就需要 Socket通信了。实际上，Socket 通信不仅可以跨⽹络与不同主机的进程间通信，还可以在同主机上进程间通信。

* 针对TCP协议通信的socket编程模型
    * 服务端和客户端初始化 socket ，得到⽂件描述符；
    * 服务端调⽤ bind ，将绑定在 IP 地址和端⼝;
    * 服务端调⽤ listen ，进⾏监听；
    * 服务端调⽤ accept ，等待客户端连接；
    * 客户端调⽤ connect ，向服务器端的地址和端⼝发起连接请求；
    * 服务端 accept 返回⽤于传输的 socket 的⽂件描述符；
    * 客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；
    * 客户端断开连接时，会调⽤close，那么服务端read读取数据的时候，就会读取到了
EOF ，待处理完数据后，服务端调⽤ close ，表示连接关闭。

这⾥需要注意的是，服务端调⽤accept时，连接成功了会返回⼀个已完成连接的socket，后续⽤来传输数据。所以，监听的socket和真正⽤来传送数据的socket，是「两个」socket，⼀个叫作监听socket，⼀个叫作已完成连接 socket。

* 针对UDP协议通信的socket编程模型

UDP是没有连接的，所以不需要三次握⼿，也就不需要像 TCP 调⽤listen和connect，但是
UDP 的交互仍然需要 IP地址和端⼝号，因此也需要bind。对于UDP来说，不需要要维护连接，那么也就没有所谓的发送⽅和接收⽅，甚⾄都不存在客户端和服务端的概念，只要有⼀个 socket 多台机器就可以任意通信，因此每⼀个 UDP 的socket 都需要 bind。

## 多线程同步

### 锁
* 自旋锁：获取不到锁，线程就一直while循环，不做任何事情，忙等待。

自旋的线程永远不会放弃CPU，所以在单核上无法使用。
* 无等待锁：获取不到锁的时候，不用自旋。把CPU让给其他线程执行。

### 信号量
参考上面的信号量章节


## 死锁

### 死锁的概念
两个线程都在等待对方释放锁，这种情况就发生了死锁。

死锁只有同时满足以下四个条件才会发生：
* 互斥条件
* 持有并等待条件
* 不可剥夺条件
* 环路等待条件

## 常见的锁

### 互斥锁与自旋锁
* 互斥锁加锁失败后，线程会释放 CPU ，给其他线程；
* ⾃旋锁加锁失败后，线程会忙等待，直到它拿到锁；

### 读写锁
读写锁适⽤于能明确区分读操作和写操作的场景。

读写锁的⼯作原理是：
* 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这⼤⼤提⾼了共享资源的访问效率，因为「读锁」是⽤于读取共享资源的场景，所以多个线程同时持有读锁也不会
破坏共享资源的数据。
* 但是，⼀旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，⽽且其他写线程的获取写锁的操作也会被阻塞。

所以说，写锁是独占锁，因为任何时刻只能有⼀个线程持有写锁，类似互斥锁和⾃旋锁，⽽读锁是共享锁，因为读锁可以被多个线程同时持有。
知道了读写锁的⼯作原理后，我们可以发现， 读写锁在读多写少的场景，能发挥出优势。

## 乐观锁与悲观锁
前⾯提到的互斥锁、⾃旋锁、读写锁，都是属于悲观锁。悲观锁做事⽐较悲观，它认为多线程同时修改共享资源的概率⽐较⾼，于是很容易出现冲突，所以访问共享资源前，先要上锁。

那相反的，如果多线程同时修改共享资源的概率⽐较低，就可以采⽤乐观锁。

乐观锁做事⽐较乐观，它假定冲突的概率很低，它的⼯作⽅式是：

先修改完共享资源，再验证这段时间内有没有发⽣冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很⾼，但是冲突的概率⾜够低的话，还是可以接受的。可⻅，乐观锁的⼼态是，不管三七⼆⼗⼀，先改了资源再说。另外，你会发现乐观锁全程并没有加锁，所以它也叫⽆锁编程。

## 网络系统

### 网络模型
为了使得多种设备能通过网络相互通信，国际标准化组织制定了OSI网络模型，该模型主要有7层：
* 应用层：负责给应用程序提供统一接口
* 表示层：负责把数据转换成兼容另一个系统能识别的格式
* 会话层：负责建立、管理和终止表示层实体之间的通信会话
* 传输层：负责端到端的数据传输
* 网络层：负责数据的路由、转发、分⽚
* 数据链路层：负责数据的封帧和差错检测，以及 MAC 寻址
* 物理层：负责在物理⽹络中传输数据帧

事实上，我们⽐较常⻅，也⽐较实⽤的是四层模型，即TCP/IP⽹络模型，Linux系统正是按
照这套⽹络模型来实现⽹络协议栈的。

TCP/IP⽹络模型共有4层，分别是应⽤层、传输层、⽹络层和⽹络接⼝层，每⼀层负责的职
能如下：
* 应⽤层：负责向⽤户提供⼀组应⽤程序，⽐如HTTP、DNS、FTP等;
* 传输层：负责端到端的通信，⽐如TCP、UDP等；
* ⽹络层：负责⽹络包的封装、分⽚、路由、转发，⽐如IP、ICMP等；
* ⽹络接⼝层：负责⽹络包在物理⽹络中的传输，⽐如⽹络包的封帧、MAC 寻址、差错检
测，以及通过⽹卡传输⽹络帧等

## 零拷贝

### DMA
直接内存访问（Direct Memory Access），在进行I/O设备和内存的数据传输的时候，数据搬运的工作直接交给DMA控制器，而CPU不参与任何与数据搬运相关的事情，这样CPU就可以去处理别的事务。

### 零拷贝实现
mmap+write
mmap：直接把内核缓冲区里的数据映射到用户空间。

零拷贝技术：所有的数据都通过DMA进行传输，不经过CPU。


## I/O多路复用

### select/poll
select 实现多路复⽤的⽅式是，将已连接的Socket都放到⼀个⽂件描述符集合，然后调⽤
select 函数将⽂件描述符集合拷⻉到内核⾥，让内核来检查是否有⽹络事件产⽣，检查的⽅式很粗暴，就是通过遍历⽂件描述符集合的⽅式，当检查到有事件产⽣后，将此 Socket 标记为可读或可写， 接着再把整个⽂件描述符集合拷⻉回⽤户态⾥，然后⽤户态还需要再通过遍历的⽅法找到可读或可写的 Socket，然后再对其处理。

所以，对于 select 这种⽅式，需要进⾏2次「遍历」⽂件描述符集合，⼀次是在内核态⾥，⼀个次是在⽤户态⾥，⽽且还会发⽣2次「拷⻉」⽂件描述符集合，先从⽤户空间传⼊内核空间，由内核修改后，再传出到⽤户空间中。

select 使⽤固定⻓度的BitsMap，表示⽂件描述符集合，⽽且所⽀持的⽂件描述符的个数是有限制的，在 Linux 系统中，由内核中的FD_SETSIZE限制，默认最⼤值为1024，只能监
听 0~1023 的⽂件描述符。

poll 不再⽤ BitsMap 来存储所关注的⽂件描述符，取⽽代之⽤动态数组，以链表形式来组织，突破了 select 的⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。

但是 poll 和 select 并没有太⼤的本质区别， 都是使⽤「线性结构」存储进程关注的 Socket集合，因此都需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。

### epoll
epoll 通过两个⽅⾯，很好解决了 select/poll 的问题。
第⼀点，epoll 在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字，把需要监控的
socket 通过epoll_ctl()函数加⼊内核中的红⿊树⾥，红⿊树是个⾼效的数据结构，增删
查⼀般时间复杂度是 O(logn)，通过对这棵⿊红树进⾏操作，这样就不需要像select/poll 每次操作时都传⼊整个socket集合，只需要传⼊⼀个待检测的socket，减少了内核和⽤户空间⼤量的数据拷⻉和内存分配。

第⼆点， epoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个
socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件列表中，当⽤户调⽤
epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率。

epoll中的ET和LT:

LT：水平触发，效率会低于ET触发，尤其在大并发，大流量的情况下。但是LT对代码编写要求比较低，不容易出现问题。LT模式服务编写上的表现是：只要有数据没有被获取，内核就不断通知你，因此不用担心事件丢失的情况。

使⽤⽔平触发模式时，当被监控的 Socket 上有可读事件发⽣时， 服务器端不断地从
epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，⽬的是告诉我们有数
据需要读取；

ET：边缘触发，效率非常高，在并发，大流量的情况下，会比LT少很多epoll的系统调用，因此效率高。但是对编程要求高，需要细致的处理每个请求，否则容易发生丢失事件的情况。

使⽤边缘触发模式时，当被监控的 Socket 描述符上有可读事件发⽣时， 服务器端只会从
epoll_wait 中苏醒⼀次，即使进程没有调⽤ read 函数从内核读取数据，也依然只苏醒⼀
次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完；





