# 操作系统内存管理
## 什么是物理内存
我们常说的物理内存大小就是指内存条的大小，但是也要看CPU地址总线的位数。

## 使用物理内存的缺点
1. 单个进程直接操作物理地址，可能破坏系统
2. 多进程运行，多个进程同时操作同一地址空间，产生并发读写问题

## 虚拟内存技术
### 虚拟内存
虚拟出来的内存，确保每个进程都有自己的地址空间，一般是4G。操作系统自动将虚拟地址空间映射到物理地址空间，程序关注的只是虚拟内存，请求的也是虚拟内存，但是真正实用的是物理内存。

### 虚拟内存技术特点
* 大的用户空间：32位虚拟地址可以访问4G
* 部分交换
* 连续性：对连续的虚拟地址来映射物理内存中的不连续的大内存缓冲区
* 安全性：不同进程的虚拟地址彼此隔离

### 虚拟内存如何映射到物理内存
CPU中有一个内存管理单元，MMU(Memory Management Unit)，虚拟内存不是直接送到内存总线，而是先给到MMU，由MMU来把虚拟地址映射到物理地址。

MMU通过页表将虚拟地址转换为物理地址，32位的虚拟地址分成两部分（虚拟页号和偏移量），MMU通过页表找到了虚拟页号对应的物理页号，物理页号+偏移量就是实际的物理地址。

页表的目的就是虚拟页面映射为物理内存的页框，页表可以理解为一个数学函数，函数的输入是虚拟页号，函数的输出是物理页号，通过这个函数可以把虚拟页面映射到物理页号，从而确定物理地址。

内存地址转换，三个步骤：
1. 把虚拟内存地址，切分成页号和偏移量
2. 根据页号，从页表里面，查询对应的物理页号
3. 拿物理地址，加上偏移量，得到物理内存地址

## CPU CACHE

### CPU CACHE分类
cpu高速缓存，处理速度比寄存器慢了一点，cpu cache分为L1 L2 L3三层，L1分成数据缓存和指令缓存，L1离cpu最近，速度最快。
如果把cpu当做大脑，寄存器就是你正在思考的事情，L1就是短期记忆，L2 L3就是长期记忆。

L1 cache通常分为数据缓存（dcache）和指令缓存（icache）。
L3通常要比L1 和L2 cache大很多，是因为L1和L2都是每个CPU核心独有，但是L3是多个cpu核心共享的。

程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核⼼独有的 L2Cache，最后进⼊到最快的 L1 Cache，之后才会被 CPU 读取。
越靠近cpu核心，访问速度越快。

### 写出让cpu跑的更快地代码 = 写出让cpu缓存命中率高的代码
* 提升数据缓存的命中率 ->代码中最好申请和访问内存连续分布
* 提升指令缓存的命中率 ->先排序后遍历 比 先遍历后排序要快，是因为CPU本身的分支预测器机制。
如果一个进程在不同核心之间切换，各个核心的缓存命中率就会受到影响。所以这也是进程和线程为啥要绑核的原因，就是为了提高cpu缓存命中率。

### cpu缓存一致性
cache和内存的一致性，分为写直达和写回
写直达：把数据同时写入内存和cache，每次都要做判断，性能受到影响。
写回：发生写操作时，新的数据被写到cache block中，只有被修改过的cache block才会写回到内存。

### 缓存一致性问题
* 写传播：某个cpu核心里的cache数据更新时，必须传播到其他核心的cache
* 事务的串行化：某个cpu核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的
* 总线嗅探机制：某个cpu核心的cache更新数据这个事件 能被其他cpu核心知道，但是不保证事务串行化。于是有了MESI协议，这个协议做到了cpu缓存一致性。

总结：
CPU 在读写数据的时候，都是在 CPU Cache 读写数据的，原因是 Cache 离 CPU 很近，读
写性能相⽐内存⾼出很多。对于 Cache ⾥没有缓存 CPU 所需要读取的数据的这种情况，
CPU 则会从内存读取数据，并将数据缓存到 Cache ⾥⾯，最后 CPU 再从 Cache 读取数
据。

⽽对于数据的写⼊， CPU 都会先写⼊到 Cache ⾥⾯，然后再在找个合适的时机写⼊到内存，
那就有「写直达」和「写回」这两种策略来保证 Cache 与内存的数据⼀致性：
写直达，只要有数据写⼊，都会直接把数据写⼊到内存⾥⾯，这种⽅式简单直观，但是性
能就会受限于内存的访问速度；

写回，对于已经缓存在 Cache 的数据的写⼊，只需要更新其数据就可以，不⽤写⼊到内
存，只有在需要把缓存⾥⾯的脏数据交换出去的时候，才把数据同步到内存⾥，这种⽅式
在缓存命中率⾼的情况，性能会更好；

当今 CPU 都是多核的，每个核⼼都有各⾃独⽴的 L1/L2 Cache，只有 L3 Cache 是多个核⼼
之间共享的。所以，我们要确保多核缓存是⼀致性的，否则会出现错误的结果。
要想实现缓存⼀致性，关键是要满⾜ 2 点：
* 第⼀点是写传播，也就是当某个 CPU 核⼼发⽣写⼊操作时，需要把该事件⼴播通知给其
他核⼼；
* 第⼆点是事物的串⾏化，这个很重要，只有保证了这个，才能保障我们的数据是真正⼀致
的，我们的程序在各个不同的核⼼上运⾏的结果也是⼀致的；

基于总线嗅探机制的 MESI 协议，就满⾜上⾯了这两点，因此它是保障缓存⼀致性的协议。
MESI 协议，是已修改、独占、共享、已实现这四个状态的英⽂缩写的组合。整个 MSI 状态
的变更，则是根据来⾃本地 CPU 核⼼的请求，或者来⾃其他 CPU 核⼼通过总线传输过来的
请求，从⽽构成⼀个流动的状态机。另外，对于在「已修改」或者「独占」状态的 Cache
Line，修改更新其数据不需要发送⼴播给其他 CPU 核⼼。


